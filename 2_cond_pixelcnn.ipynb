{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdbc054326ba6339cc11118795945782",
     "grade": false,
     "grade_id": "cell-3c98ddabe9e64f07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> May 15, 2024 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "\n",
    "# Exercise 2. Conditional generation with PixelCNN\n",
    "\n",
    "The goal of this exercise is to do conditional generation with the PixelCNN model.\n",
    "The basic idea of the conditioning is described in Section 2.3 of [this paper](https://arxiv.org/pdf/1606.05328.pdf). However, we will use a much simpler model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04f640fbb285ec75e54ef46a7840ae25",
     "grade": true,
     "grade_id": "cell-a54f4cac48b8daec",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b79b793e3771be4f29f1e582f8d5dfc6",
     "grade": false,
     "grade_id": "cell-6eeffe49baead231",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "767ca562df4a44a61a6bd37995d6c9c2",
     "grade": false,
     "grade_id": "cell-94c5742c02305758",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "In this exercise, we use standard MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c68960f7f54eb8281e78b61a10c0e5d3",
     "grade": false,
     "grade_id": "cell-532a4922e89ce5f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a9ae72ff8bf9476ad01550f0b1426a9",
     "grade": false,
     "grade_id": "cell-72f0a284a46f0d97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "tools.show_images(images[:8], ncol=4, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff46bf85ab2c828cdc5995b4efe62dd2",
     "grade": false,
     "grade_id": "cell-a4de8a0f0588b4df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Masked convolutional layer\n",
    "\n",
    "In the cell below, copy the implementation of the `MaskedConv2d` from the PixelCNN notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ead7030b2311293a95080875cbe940b0",
     "grade": false,
     "grade_id": "MaskedConv2d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Module):\n",
    "    # YOUR CODE HERE\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, blind_center=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_channels (int): Number of input channels.\n",
    "          out_channels (int): Number of output channels.\n",
    "          kernel_size (int): Kernel size similar to nn.Conv2d layer.\n",
    "          blind_center (bool): If True, the kernel has zero in the center.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(MaskedConv2d, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=int((kernel_size - 1) / 2), bias=False)\n",
    "        \n",
    "        self.register_buffer('mask', self.conv.weight.data.clone())\n",
    "        _, _, kH, kW = self.conv.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        \n",
    "        if blind_center:\n",
    "            self.mask[:, :, kH // 2 + 1:] = 0\n",
    "            self.mask[:, :, kH // 2, kW // 2:] = 0\n",
    "        else:\n",
    "            self.mask[:, :, kH // 2 + 1:] = 0\n",
    "            self.mask[:, :, kH // 2, kW // 2 + 1:] = 0\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, in_channels, height, width): Input images.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, out_channels, height, width): Output images.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.conv.weight.data *= self.mask\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14bf4cda7da19711b1a7ff2db9be1018",
     "grade": false,
     "grade_id": "cell-aaa542146c8ce33d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Conditional PixelCNN\n",
    "\n",
    "Conditional PixelCNN models allows to generate images of a desired class. This can be achieved by providing the desired class label to every layer of the PixelCNN model. In this notebook, we do it in the following way: the input of each masked convolutional layer is:\n",
    "$$\\mathbf{x} + \\mathbf{W} \\mathbf{h}$$\n",
    "where\n",
    "  * $\\mathbf{x}$ is the output of the previous layer\n",
    "  * $\\mathbf{h}$ is a 10-dimensional one-hot coded vector of the desired class\n",
    "  * $\\mathbf{W}$ is $c \\times 10$ matrix (parameter of a fully-connected layer), where $c$ is the number of input channels in the masked convolutional layer.\n",
    "\n",
    "You need to implement the conditional PixelCNN model in the cell below.\n",
    "\n",
    "Notes:\n",
    "* Use an architecture *similar* to the PixelCNN architecture in the first notebook. The architecture is not exactly same because of the extra inputs $\\mathbf{h}$. Please use the same kernel sizes as in the first notebook because we test the receptive fields.\n",
    "* The parameters $\\mathbf{W}$ are not shared across layers. Thus, you need as many parameters $\\mathbf{W}$ as you have masked convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7c3a3ac3044bd44279be356576cb5a2",
     "grade": false,
     "grade_id": "conditional_pixel_cnn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConditionalPixelCNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, kernel_size=7):\n",
    "        \"\"\"PixelCNN model for conditional generation.\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(ConditionalPixelCNN, self).__init__()     \n",
    "        self.skip_in = nn.Linear(10, 1)\n",
    "        \n",
    "        self.block_in = nn.Sequential(\n",
    "            MaskedConv2d(1, n_channels, kernel_size, blind_center=True),\n",
    "            nn.BatchNorm2d(n_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.maskedconv_layers = nn.ModuleList()\n",
    "        self.skip_layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(7):\n",
    "            self.maskedconv_layers.append(\n",
    "                nn.Sequential(\n",
    "                    MaskedConv2d(n_channels, n_channels, kernel_size, blind_center=False),\n",
    "                    nn.BatchNorm2d(n_channels),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            self.skip_layers.append(nn.Linear(10, 1))\n",
    "            \n",
    "        self.out_skip = nn.Linear(10, 1)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 256, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"Compute logits of the conditional probabilities p(x_i|x_1, ..., x_{i-1}) of the PixelCNN model.\n",
    "        \n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Tensor of input images.\n",
    "          labels of shape (batch_size): LongTensor of the desired classes of the generated samples.\n",
    "        \n",
    "        Returns:\n",
    "          logits of shape (batch_size, 256, 28, 28): Tensor of logits of the conditional probabilities\n",
    "                                                      for each pixel.\n",
    "        \n",
    "        NB: Do not use softmax nonlinearity after the last layer.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "         # YOUR CODE HERE\n",
    "        y_onehot = torch.FloatTensor(labels.shape[0], 10).to(labels.device)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "        \n",
    "        out = self.block_in(x)\n",
    "        \n",
    "        for maskedconv, skip in zip(self.maskedconv_layers, self.skip_layers):\n",
    "            wh2 = skip(y_onehot).unsqueeze(2).unsqueeze(3).repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "            out = maskedconv(out + wh2)\n",
    "        \n",
    "        out = self.out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3441d674d78988985cc12ac6c1ecdf4",
     "grade": false,
     "grade_id": "cell-6ceba5f92fe75b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_ConditionalPixelCNN_shapes():\n",
    "    net = ConditionalPixelCNN(n_channels=64, kernel_size=7)\n",
    "\n",
    "    batch_size = 2\n",
    "    x = torch.ones(batch_size, 1, 28, 28)\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long)\n",
    "    y = net(x, labels)\n",
    "    assert y.shape == torch.Size([batch_size, 256, 28, 28]), f\"Bad y.shape: {y.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_ConditionalPixelCNN_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66e1852e3ede50cfb5aac454a9e66142",
     "grade": false,
     "grade_id": "cell-33f0e5430af65349",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss function for training conditional PixelCNN\n",
    "\n",
    "The `loss_fn()` function is identical to the `loss_fn()` from the PixelCNN notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dbe63c296ea1dff830b1f7b1abac44b",
     "grade": false,
     "grade_id": "loss_fn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, x):\n",
    "    \"\"\"Compute loss of the conditional PixelCNN model. Please see PixelCNN.loss for more details.\n",
    "\n",
    "    Args:\n",
    "      logits of shape (batch_size, 256, 28, 28): Logits of the conditional probabilities\n",
    "                  p(x_i | x_1,...,x_{i-1}) of the 256 intensities of pixel x_i computed using all\n",
    "                  previous pixel value x_1,...,x_{i-1}.\n",
    "      x of shape (batch_size, 1, 28, 28): Images used to produce `generated_x`. The values of pixel\n",
    "                  intensities in x are between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "      loss: Scalar tensor which contains the value of the loss.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    target = torch.autograd.Variable(x[:, 0, :, :] * 255).long()\n",
    "    target.to(device)\n",
    "    return criterion(logits, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61130647ceae27ef8615e0975fe103ec",
     "grade": false,
     "grade_id": "cell-8e9892706a9d8986",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generation procedure\n",
    "\n",
    "The `generate()` function is *almost* identical to the `generate()` function from the PixelCNN notebook. It additionally receives the labels of the desired classes so that they can be used in the forward computations of the conditional PixelCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4294be8877eb96082e905c7e2be1f00d",
     "grade": false,
     "grade_id": "generate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(net, labels, image_size=(28, 28), device='cpu'):\n",
    "    \"\"\"Generate samples using a trained conditional PixelCNN model.\n",
    "    Note: use as device labels.device.\n",
    "\n",
    "    Args:\n",
    "      net: Conditional PixelCNN model.\n",
    "      labels of shape (n_samples): Long tensor of the desired classes of the generated samples.\n",
    "      image_size: Tuple of image size (height, width).\n",
    "      device:     Device to use.\n",
    "    \n",
    "    Returns:\n",
    "      samples of shape (n_samples, 1, height, width): Generated samples.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "\n",
    "    samples = torch.Tensor(labels.shape[0], 1, image_size[0], image_size[1]).to(device)\n",
    "    samples.fill_(0)\n",
    "\n",
    "    for i in range(image_size[0]):\n",
    "        for j in range(image_size[1]):\n",
    "            out = net(samples, labels)\n",
    "            probs = F.softmax(out[:, :, i, j], dim=-1).data\n",
    "            samples[:, :, i, j] = torch.multinomial(probs, 1).float() / 255.0\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4d31b69403ec5cf3f60e234968e9230",
     "grade": false,
     "grade_id": "cell-85f2af389e3b1c61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bba666955a640819c110ed3d0a77e110",
     "grade": false,
     "grade_id": "cell-d0de5c83645b3502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConditionalPixelCNN(\n",
       "  (skip_in): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (block_in): Sequential(\n",
       "    (0): MaskedConv2d(\n",
       "      (conv): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maskedconv_layers): ModuleList(\n",
       "    (0-6): 7 x Sequential(\n",
       "      (0): MaskedConv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (skip_layers): ModuleList(\n",
       "    (0-6): 7 x Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       "  (out_skip): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create network\n",
    "net = ConditionalPixelCNN(n_channels=64, kernel_size=7)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03b52c06f90c42152780f3e36b7a67ff",
     "grade": false,
     "grade_id": "cell-481bb5e1d1ab36b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot generated samples for an untrained model\n",
    "# Note: generation on CPU may take a significant amount of time\n",
    "if not skip_training:\n",
    "    labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "    samples = generate(net, labels, device=device)\n",
    "    tools.show_images(samples, ncol=10, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4ed8858a6815632f94f200eed72838b",
     "grade": false,
     "grade_id": "cell-cf49609428a403c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.001\n",
    "* Number of epochs: 11.\n",
    "\n",
    "Hints:\n",
    "- The loss at convergence can reach 0.63. We test that the training loss is below 0.71 in the hidden test.\n",
    "- Please use this code to plot 120 generated samples after each epoch. This will allow you to track the training progress.\n",
    "```\n",
    "# Generate samples\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "    samples = generate(net, labels, device=device)\n",
    "    tools.show_images(samples, ncol=10, cmap='binary')\n",
    "```\n",
    "- The generated images should be of great quality but you should definitely recognize the desired classes of the digits.\n",
    "- **Do not forget to set the model into the training mode by `net.train()` before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eee972e75dfc82217d977fa7bab26b97",
     "grade": false,
     "grade_id": "cond_pixel_cnn_training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(11):\n",
    "        tot_loss = 0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            img, label = data\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "\n",
    "            out = net(img, label)\n",
    "            loss = loss_fn(out, img)\n",
    "            loss.backward()\n",
    "\n",
    "            optim.step()\n",
    "\n",
    "            tot_loss += loss\n",
    "        \n",
    "        # Generate samples\n",
    "        with torch.no_grad():\n",
    "            labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "            samples = generate(net, labels, device=device)\n",
    "            tools.plot_generated_samples(samples, ncol=10)\n",
    "\n",
    "        print('Epoch:{} , loss: {}'.format(epoch, tot_loss.item() / len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '2_cond_pixelcnn.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c756b0c7846f2ec4fbc373a035aa0ea",
     "grade": false,
     "grade_id": "cell-36010d91cd891307",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    net = ConditionalPixelCNN(n_channels=64, kernel_size=7)\n",
    "    tools.load_model(net, '2_cond_pixelcnn.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b4afefc2e69fd11b922010e72d32b44",
     "grade": false,
     "grade_id": "cell-560767c43e2ad560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c64c8cff98f5f4830b70ef0e29d3712",
     "grade": false,
     "grade_id": "cell-fecbc19f46a95e57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "        samples = generate(net, labels, device=device)\n",
    "        torch.save(samples, '2_cond_pixelcnn_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('2_cond_pixelcnn_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "tools.show_images(samples, ncol=10, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52886498843d697745a2ab75f07d04e0",
     "grade": true,
     "grade_id": "cell-f0fc9ef5c12c97fc",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the training loss of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73b516a0e610ef1cf013f531a2641884",
     "grade": false,
     "grade_id": "cell-25eed043aff8f44a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this notebook, we learned how to train a conditional PixelCNN model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
